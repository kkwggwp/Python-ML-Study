7/2 오전 복습
사이킷런
 - 머신러닝 라이브러리
 - 지도학습 / 비지도 학습 / 전처리 도구 / 편의성 도구들을 제공하는 키트

[머신러닝 7단계]
1. 문제 정의
인공지능 구현 전 기획 단계 - 계획을 세우는 단계
 - 우리 서비스에 인공지능이 필요할까?
 - 어떤 서비스에 무슨 인공지능을 사용할까?
 - 데이터 확보는 어떻게 하지?
 - 무슨 데이터가 필요할까?

2. 데이터 수집
데이터를 분석하려면 데이터가 필요하다! - 데이터를 확보합시다.
 - 파일로 다운로드(CSV / JSON / XML 등등등)
 - 데이터베이스에서 자료 확보
 - 웹 크롤링 : 자동화 수집도구 사용
 - 센서 또는 IOT기기 활용 데이터 수집
 - 설문 조사를 통해 자료 확보

3. 데이터 전처리 - 중요!!! 
데이터를 살펴보고 데이터를 깔끔하게 정리하자!
> 컴퓨터가 데이터를 잘 보고 이해할 수 있도록 우리가 정리해주자!
 - 결측치 이상치 처리 : 결측치 - 비어있는 값 / 이상치 - 최대값 / 최소값을 넘는 이상한 값
 - Encoding : 범주값 -> 수치값 / Binning : 수치값 -> 범주값
 - Transform : 새로운 특성을 추가 / 값을 변환
 - Data Scailing : 표준화 / 정규화 -> 데이터의 특성값을 일정한 기준으로 통일

4. EDA(탐색적 데이터 분석)
 - 상관계수, 사분위수, 기술통계
 > 각각의 특성간의 연관관계를 확인 - 특성간의 영향도를 파악
 > 데이터의 분포를 살펴보고 현재 데이터가 어떤 상황인지 파악
 > 평균 / 최빈값 / 중앙값 / 최대 / 최소 / 표준 편차들을 살펴보고 통계 분석 진행
 - 데이터가 말하고자 하는 인사이트(정보) 캐치
 - 가설 설정 : 통계치로 상황을 판단하고 결과 예상 

5. 모델 정의 및 하이퍼 파라미터 조절
 - 우리가 어떤 인공지능 알고리즘 / 신경망을 쓸 것인가?
 > KNN / Tree / 선형 회귀 / 선형 분류 / MLP / CNN / RNN 등
 > 모델이 데이터에 맞춰서 잘 반응할 수 있도록 하이퍼 파라미터 튜닝을 진행
 > 과대 / 과소 적합을 해소하고 일반화 성능을 올려보겠다.

6. 모델 학습 / 예측
 - 모델 학습 함수 : 모델명.fit(X_train, y_train)
 - 모델 예측 함수 : 모델명.predict(X_test)
 * 용어 정리
 1. X - 문제 데이터
 2. y - 정답 데이터
 3. train - 훈련 데이터
 4. test - 평가 데이터
 ** 조합 **
 X_train : 훈련용 문제 데이터
 X_test : 평가용 문제 데이터
 y_train : 훈련용 정답 데이터
 y_test : 평가용 정답 데이터

 train / test 비율 - 70% / 30%

 - train_test_split() : 데이터를 랜덤으로 섞어서 훈련 데이터 셋트와 평가 데이터 셋트로 분할

7. 모델 평가
 - 평가 지표를 이용해서 모델의 성능을 측정
 - sklearn.metrics : 평가지표 모음집
 1. 분류 : accuracy_score / recall_score / precision_score / F1-Score
 2. 회귀 : MSE / MAE / MAPE / RMSE / R2-Score

[모델의 신뢰도 성능 측정]
일반화 - 훈련 데이터 셋트의 성능과 평가 셋트의 성능이 비슷한 상태
> 훈련 셋트에서 찾은 규칙으로 평가 셋트에 반영해봤더니 규칙이 잘 찾아져서 
   답을 잘 맞춘상태

과대적합 - 훈련 데이터의 셋트는 성능이 매우 뛰어나나 평가 데이터 셋트의 성능이 낮음
> 훈련 셋트에서 뛰어난 성능으로 학습을 완료하였으나 새로운 평가 데이터셋트에 규칙이
   맞지않아서 정답을 제대로 예측하지 못하는 상태

과소적합 - 훈련 데이터 학습이 제대로 이뤄지지 않아서 규칙이 세워지지 않음
> 학습이 제대로 이뤄지지 않아서 규칙이 만들어지지 않았다. 반영할 규칙이 불완전하기 
   때문에 예측 또한 제대로 이뤄지지 않는 상태.
 
KNN(K-Nearest-Neighbors / 최근접 이웃 알고리즘)
 - 유유상종 / 끼리끼리 모인다
 - 데이터는 비슷한 특성을 가진 것들끼리 모이는 습성이 있음
 - 이 특성을 학습과 예측에 이용하겠다.
 > 새로운 데이터가 등장하면 우리가 지정한 이웃의 갯수를 확인
 > 새롭게 등장한 데이터에서 가장 가까운 순서대로 이웃의 갯수만큼 데이터를 확인
 > 확률 정보를 통해 최종 예측 진행
 - n_neighbors : 주변 이웃을 몇개나 확인할 것인가? / KNN의 대표 하이퍼 파라미터
 ** 추가 내용 **
 > 내부 알고리즘에서 새롭게 등장한 데이터와 기존 학습된 데이터 간의 근접도는 어떻게 
    알아볼까?
  - 사용하는 지표 - 거리
  > 거리를 구하는 공식
  - 살펴봐야 하는 하이퍼 파라미터 2개 
  > metric : 민코프스키 거리 공식
    맨해튼 거리공식과 유클리디언 거리 공식을 일반화시켜 통합한 거리 공식
  > p : 민코프스키 거리 공식에 적용되서 맨해튼 거리공식과 유클리디언 거리공식을 선택
    p = 1 : 맨해튼 거리 공식
    p = 2 : 유클리디언 거리 공식
    KNN 모델에서 사용하는 기본값 : p = 2(유클리디언 거리 공식)



